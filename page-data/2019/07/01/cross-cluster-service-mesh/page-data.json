{"componentChunkName":"component---src-templates-blog-post-js","path":"/2019/07/01/cross-cluster-service-mesh","webpackCompilationHash":"95c6849230ad8a5f4f34","result":{"data":{"markdownRemark":{"id":"f1c13765-400a-5d71-9dbf-8bf5557c8ba2","excerpt":"A multi cloud service mesh with Istio This post guide you to create a multi cloud service mesh with Istio on Kubernetes clusters in Amazon…","html":"<h1 id=\"a-multi-cloud-service-mesh-with-istio\"><a href=\"#a-multi-cloud-service-mesh-with-istio\" aria-label=\"a multi cloud service mesh with istio permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A multi cloud service mesh with Istio</h1>\n<p><em>This post guide you to create a multi cloud service mesh with Istio on Kubernetes clusters in Amazon and Google cloud.</em></p>\n<p style=\"text-align: right\">\n  <a href=\"https://github.com/npalm/cross-cluster-mesh-postcard\" target=\"sourcecode\">\n  <i class=\"fab fa-github\" style=\"font-size: 200%\">&nbsp;</i>Source code for this post</a></p>\n<h2 id=\"introduction\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>The last years we have seen a huge adoption of micro services architectures. Typically micro services brings a lot ff benefits such as flexibility, modularity, autonomy. But deploying and managing micro services architectures brings other difficulties. How dow you know what is running, how do you know your services are compliant? Another pattern that we see is that micro services ar typically heavy loaded with common dependencies for logging, authentication, authorization, tracing and many more cross cutting concerns.</p>\n<p>A service mesh brings transparency to the chaos of micro services. A mesh can help with implementing, enforcing and managing requirements such as authentication, authorization, traceability and, data integrity. It also provides features as orchestration and collection of telemetry. There are currently several service meshes out, for example <a href=\"https://aws.amazon.com/app-mesh/\">App Mesh</a> from Amazon, <a href=\"https://www.consul.io/\">Consol</a> from HashiCorp, <a href=\"https://linkerd.io/\">Linkerd</a> from the CNNF and <a href=\"https://istio.io/\">Istio</a> launched by IBM, Lyft and Google in 2016. Istio is a fully open source solution based on the high performance proxy <a href=\"https://www.envoyproxy.io/\">Envoy</a>.</p>\n<p>Another trend in the industry is multi cloud or hybrid cloud. Confusing terms, no clear definitions. But it look likes common sense when we speaking about multi cloud we point to combining public clouds. And hybrid cloud is when you mix and match public with private cloud. When you start running cross cloud clusters it becomes even harder to manage all your micro services. Be confident that policies are implemented well or compliant. In this multi / hybrid topology, abstraction from cross cutting concerns to a mesh becomes even more important. In this blog we go to build a multi cloud <a href=\"https://kubernetes.io/\">Kubernetes</a> cluster with an Istio service mesh.</p>\n<h2 id=\"a-bit-more-about-a-service-mesh\"><a href=\"#a-bit-more-about-a-service-mesh\" aria-label=\"a bit more about a service mesh permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A bit more about a Service Mesh</h2>\n<p>Before we dive into building a multi cloud service mesh, a few words about how a mesh works. An Istio mesh consists of two parts. A data plane, intelligent proxies (Envoy) deployed as sidecars. Those proxies mediate and control the network traffic. The second component is the control plane which manages and configures the proxies, and enforce policies.</p>\n<p><img src=\"/fdc858d2c1e5605229e86884e3838713/istio-arch.svg\" alt=\"istio-architecture\"></p>\n<p>To create a cross cluster mesh with Istio there are two topologies. In the first scenario there is a single control plain that controls all the cluster. In the second scenario a single control plain is deployed to every cluster and you have to ensure the same configuration is pushed to each cluster. In this post we will create an example based on the second option, a control plane in every cluster.</p>\n<p><img src=\"/4463b084153941d1edea7583fe0befcf/multicluster-with-gateways.svg\" alt=\"istio-multi-cluster\"></p>\n<h2 id=\"building-a-cross-cluster-mesh\"><a href=\"#building-a-cross-cluster-mesh\" aria-label=\"building a cross cluster mesh permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Building a cross cluster mesh</h2>\n<p>Lets get started with building a multi cloud service mesh. A quite similar similar example as below is available on my <a href=\"https://github.com/npalm/cross-cluster-mesh-postcard\">GitHub</a>. The example on GitHub is scripted with a set of simple shell scripts and created 3 clusters in 2 clouds. For this post we limited our selves to just 2 clusters in 2 clouds.</p>\n<p>We will create 2 clusters and install in both clusters the Istio service mesh, one cluster on AWS (EKS) and the second on Google (GKE). For creating clusters you need to setup your environment with the right tools and credentials. For AWS the <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html\">AWS CLI</a> is required, for Google you need the <a href=\"https://cloud.google.com/sdk/\">Google Cloud SDK</a>. Furthermore you need to install <a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\">kubectl</a> to interact with Kubernetes. And <a href=\"https://helm.sh/\">helm</a> as packagem manager for Kubernetes.</p>\n<h3 id=\"setup-and-configure-eks-cluster\"><a href=\"#setup-and-configure-eks-cluster\" aria-label=\"setup and configure eks cluster permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setup and configure EKS cluster</h3>\n<p>First we create EKS clusters with <code class=\"language-text\">eksctl</code>. But cluster has a quite minimal configuration. See the page of <a href=\"https://eksctl.io/\">weaveworks ekstcl</a> or <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html\">AWS</a> fom more details. Creating a cluster roughly takes 20 minutes. With the command below we create a default EKS cluster, with only one node it’s own VPC.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">export KUBECONFIG=kubeconfig-istio-1.config\nexport CLUSTER_NAME=mesh-1\neksctl create cluster \\\n  --name $CLUSTER_NAME \\\n  --region eu-central-1 \\\n  --version 1.13 \\\n  --node-type t3.medium \\\n  --nodes 2 \\\n  --nodes-min 2 \\\n  --nodes-max 4 \n  --node-ami auto \\\n  --kubeconfig=$KUBECONFIG \\\n  --tags &quot;environment=multi-cloud-mesh&quot;\n\nkubectl get nodes</code></pre></div>\n<p>You should now have a Kubernetes cluster running on AWS. Next we download, install and configure Istio for our service mesh. In the steps below we use for simplicity the sample certificates provided by the Istio distribution. Should I really mention that you should replace those certificates for a real life setup…</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Download Istio\nexport ISTIO_VERSION=1.1.9\ncurl -L https://git.io/getLatestIstio | sh -\nexport PATH=&quot;$PATH:$PWD/istio-1.1.9/bin&quot;\n\n# Create namespace and install demo certificates \nkubectl apply -f istio-$ISTIO_VERSION/install/kubernetes/namespace.yaml\nkubectl create secret generic -n istio-system cacerts \\\n  --from-file=istio-$ISTIO_VERSION/samples/certs/ca-cert.pem \\\n  --from-file=istio-$ISTIO_VERSION/samples/certs/ca-key.pem \\\n  --from-file=istio-$ISTIO_VERSION/samples/certs/root-cert.pem \\\n  --from-file=istio-$ISTIO_VERSION/samples/certs/cert-chain.pem\n\n# Create a service account for helm.\nkubectl create -f \\\n  istio-$ISTIO_VERSION/install/kubernetes/helm/helm-service-account.yaml\nhelm init --service-account tiller\n\n# Install the Istio resources\nhelm install istio-$ISTIO_VERSION/install/kubernetes/helm/istio-init \\\n  --name istio-init --namespace istio-system</code></pre></div>\n<p>The last step could take a minute or so, check with <code class=\"language-text\">kubectl get crds | grep &#39;istio.io&#39; | wc -l</code> if the Istio custom resources are created. Once finished there should be 53 custom resources created. The last step for installing the service mesh is to create the Istio control plan.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm install --name istio --namespace istio-system \\\n  istio-$ISTIO_VERSION/install/kubernetes/helm/istio \\\n  --values istio-$ISTIO_VERSION/install/kubernetes/helm/istio/example-values/values-istio-multicluster-gateways.yaml </code></pre></div>\n<p>For this example we simply enable sidecar injection for every pod in the default namespace. The sidecar will function as proxy and intercepts all network traffic to the containers in the pad.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl label namespace default istio-injection=enabled</code></pre></div>\n<p>Services in a local Kubernetes share a common DNS suffix (e.g. <code class=\"language-text\">svc.cluster.local</code>). To ba able to route our remote service we have to stub the Kubernetes DNS for the domain name <code class=\"language-text\">.glabal</code>. Service in a remote cluster can then be addressed with the naming convention <code class=\"language-text\">&lt;name&gt;.&lt;namespace&gt;.&lt;global&gt;</code>. Therefore we need to stub the Kubernetes DNS. EKS is using CoreDNS, so we add the config map below.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns\n  namespace: kube-system\ndata:\n  Corefile: |\n    .:53 {\n        errors\n        health\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n           pods insecure\n           upstream\n           fallthrough in-addr.arpa ip6.arpa\n        }\n        prometheus :9153\n        proxy . /etc/resolv.conf\n        cache 30\n        loop\n        reload\n        loadbalance\n    }\n    global:53 {\n        errors\n        cache 30\n        proxy . $(kubectl get svc -n istio-system istiocoredns -o jsonpath={.spec.clusterIP})\n    }\nEOF</code></pre></div>\n<p>The service mesh on EKS is now ready to start serving applications.</p>\n<h3 id=\"the-postcard-sample-application\"><a href=\"#the-postcard-sample-application\" aria-label=\"the postcard sample application permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Postcard sample application</h3>\n<p>In this blog post we use a simple polyglot postcards application. It is always fun to write an application in yet another language. The postcard application consists of twe services. The first service is the <a href=\"https://github.com/npalm/cross-cluster-mesh-postcard/tree/master/greeter\">greeter</a>, the greeter is written in NodeJS and generates a webpage with a postcard. The message on the postcard should be provided by the second application, the <a href=\"https://github.com/npalm/cross-cluster-mesh-postcard/tree/master/messenger\">messenger</a>. THe messenger is a Rust application that will run on the second cluster. I returns a string message based on configuration.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.88620199146515%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABhElEQVQoz31SW27CQAzcF2qAVhBSQiCEQB4kbZH4QUIgzsUnPxyEo9Lx4tC0gVoa2Vrb48daCCFcoC+aooAWYAANyD8+zb4X1sZ6pJRDqHcOrJI6wCewBL6AlMkr8YEC+GA/xQ2tZzwe681mIx90KLIsU71ejypLY0zdRfGq3++r1WqlfiVNp1M9mUwoYAAkQATEZDuO093v9w+LkSRJIsMwtJVALpQC92Kx0OzvMhmNHwAedZimKRE6VBsYMajg6/F4FHEca570xhJFkeEOG7JcLlUQBIqLZUAILICcPuF8PtNaNMf+EI5GI1nbjSThkbTruurZyNQIVmZ4dfcu9LOEw+EgsUdK8HgNJf/sG50NxpWz2czmw/4hhHR4T3RTPdba931zvV4r/so34DsUtN+yLC0h9C1qPp8TYRtmmzvJ2Vae57VqhA3BuiStjO37rel/zkKfTidro+j9HWuwGuM2CYuiUNUv2zuqJed5ri6Xi7Xrne52O6u3261Yr9c2F9q+fQOLCCuHsrZCAAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/6854a1ea032315cd528b587ac93d763f/cc182/postcard-app.webp 148w,\n/static/6854a1ea032315cd528b587ac93d763f/f7e40/postcard-app.webp 295w,\n/static/6854a1ea032315cd528b587ac93d763f/1a2f4/postcard-app.webp 590w,\n/static/6854a1ea032315cd528b587ac93d763f/5bf42/postcard-app.webp 703w\"\n          sizes=\"(max-width: 590px) 100vw, 590px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/6854a1ea032315cd528b587ac93d763f/cf440/postcard-app.png 148w,\n/static/6854a1ea032315cd528b587ac93d763f/d2d38/postcard-app.png 295w,\n/static/6854a1ea032315cd528b587ac93d763f/b9e4f/postcard-app.png 590w,\n/static/6854a1ea032315cd528b587ac93d763f/afda5/postcard-app.png 703w\"\n          sizes=\"(max-width: 590px) 100vw, 590px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/6854a1ea032315cd528b587ac93d763f/b9e4f/postcard-app.png\"\n          alt=\"sequence\"\n          title=\"sequence\"\n          loading=\"lazy\"\n        />\n      </picture>\n    </span></p>\n<p>The greeter app will print an error message in case the messenger is not available. We deploy now the greeter to the Kubernetes cluster on AWS. We create a standard deployment for the pod, a service, a Istio Gateway, and a Istio Virtual service. The Istio resources are created to make the postcard app public available via an ingress. You can check out the configuration files <a href=\"https://github.com/npalm/cross-cluster-mesh-postcard/tree/master/mesh/demo/greeter\">here</a>. During deployment we update the configuration with name of the cluster.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Deploy greeter pod and service\ncurl -L \\\n  https://raw.githubusercontent.com/npalm/cross-cluster-mesh-postcard/master/mesh/demo/greeter/greeter.yaml \\\n  | sed &quot;s/CLUSTER_NAME/${CLUSTER_NAME}/&quot; | kubectl apply -f -\n\n# create gateway for greeter service\nkubectl apply -f \\\n  https://raw.githubusercontent.com/npalm/cross-cluster-mesh-postcard/master/mesh/demo/greeter/gateway.yaml</code></pre></div>\n<p>Once deployed we should already be able to see our postcard via a browser. You can construct the URL with the command below. It can taka few minutes before Load Balancer is ready to accept traffic.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">export ISTIO_INGRESS=$(kubectl -n istio-system \\\n  get service istio-ingressgateway \\\n  -o jsonpath=&#39;{.status.loadBalancer.ingress[0].hostname}&#39;)\nopen http://${ISTIO_INGRESS}/greeter</code></pre></div>\n<p>The postcard shows no message from the second cluster. But our greeter app is up and running. The next steps is creating the second cluster.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.25543478260869%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsSAAALEgHS3X78AAABn0lEQVQoz4VSS0vDQBjMr+4PEAS9C73pRTyoBw+Cl3hQRNCL0pOitEl2m2Q370eTbJ7ONjFWW3AIYV/zzXyzq7Tf6Lqu/1NKwzD0PY9znuVZURSEGEEQYP/05nbvaP/kcnqu3uGk0m3BdV3f923LCgK/qqqmadI0Xa1W2LpW1cnB5PPtIg4JhJQoigghSZqOykCWZVEU4g9ZLIJZCoH1++eH6dnhlXpc5Ewqw6FhGI7rRGvEcQyHEOxLpL+L5iInbKmbpCgySYZDNMk4M4iBgWma8/kcNOxBFrUsy9I0TYiiruuqrJq6wYfqqLij5xEgMGajHCVEWyx0XXccJ0kSVER1SR7TRjDtBnplhJfneZpIyNjWyQHg4/xu5Z4shICUJK+BQZatklgqYzrYbrt2jGSTDG/9Df0xNVr7p2eobaY9lO6GqRLHEfrBS4LJsiyRKHRAQ6bbtNEXjg3KmIDmBwHnzLZt10Wnjue6eAK4edxlKDFc/nBeyMejzF4eZ69P3KT6xzunxDZ0Rg3HXHqWxZfU4wzZoHW0D0c/0q1M4QvHg+eDTp+GfwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/65a524c772eee3938ab0a86e19810340/cc182/postcard-1.webp 148w,\n/static/65a524c772eee3938ab0a86e19810340/f7e40/postcard-1.webp 295w,\n/static/65a524c772eee3938ab0a86e19810340/1a2f4/postcard-1.webp 590w,\n/static/65a524c772eee3938ab0a86e19810340/4837b/postcard-1.webp 885w,\n/static/65a524c772eee3938ab0a86e19810340/2f819/postcard-1.webp 1180w,\n/static/65a524c772eee3938ab0a86e19810340/e71d5/postcard-1.webp 1472w\"\n          sizes=\"(max-width: 590px) 100vw, 590px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/65a524c772eee3938ab0a86e19810340/cf440/postcard-1.png 148w,\n/static/65a524c772eee3938ab0a86e19810340/d2d38/postcard-1.png 295w,\n/static/65a524c772eee3938ab0a86e19810340/b9e4f/postcard-1.png 590w,\n/static/65a524c772eee3938ab0a86e19810340/f9b6a/postcard-1.png 885w,\n/static/65a524c772eee3938ab0a86e19810340/2d849/postcard-1.png 1180w,\n/static/65a524c772eee3938ab0a86e19810340/cef07/postcard-1.png 1472w\"\n          sizes=\"(max-width: 590px) 100vw, 590px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/65a524c772eee3938ab0a86e19810340/b9e4f/postcard-1.png\"\n          alt=\"postcard\"\n          title=\"postcard\"\n          loading=\"lazy\"\n        />\n      </picture>\n    </span></p>\n<h3 id=\"setup-and-configure-gke-cluster\"><a href=\"#setup-and-configure-gke-cluster\" aria-label=\"setup and configure gke cluster permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setup and configure GKE cluster</h3>\n<p>For the second cluster we create a GKE cluster on Google Cloud. You can replace by a second cluster in Amazon or one in another cloud. The first step is similar to creating a cluster in AWS but now one in Google. Open a new terminal to avoid conflicting environment variables.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">export KUBECONFIG=kubeconfig-istio-2.config\nexport CLUSTER_NAME=mesh-2\ngcloud container clusters create \\\n    --machine-type n1-standard-4 \\\n    --num-nodes 1 --enable-autoscaling \\\n    --min-nodes 1 --max-nodes 5 \\\n    --addons HttpLoadBalancing,HorizontalPodAutoscaling,KubernetesDashboard \\\n    --cluster-version 1.13 --zone europe-west3-b \\\n    $CLUSTER_NAME\n\nkubectl create clusterrolebinding mt-admin --user &quot;$(gcloud config get-value core/account)&quot; --clusterrole cluster-admin\n\nkubectl get nodes</code></pre></div>\n<p>The cluster will created in roughly 5 minutes. Next you have to install Istio. The steps are exactly the same as above. Only the last step where we configure the DNS is different since GKE use kube-dns instead of core-dns. Execute the command below to stub  the DNS.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\ndata:\n  stubDomains: |\n    {&quot;global&quot;: [&quot;$(kubectl get svc -n istio-system istiocoredns -o jsonpath={.spec.clusterIP})&quot;]}\nEOF</code></pre></div>\n<h3 id=\"the-postcard-sample-application---part-ii\"><a href=\"#the-postcard-sample-application---part-ii\" aria-label=\"the postcard sample application   part ii permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Postcard sample application - part II</h3>\n<p>On the second cluster we deploy the messenger app that simply sends a message back. The message can be configures via an environment variable. Install the messenger the app with the <code class=\"language-text\">kubectl</code> command below.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Deploy greeter pod and service\ncurl -L \\\n  https://raw.githubusercontent.com/npalm/cross-cluster-mesh-postcard/master/mesh/demo/messenger/messenger.yaml \\\n  | sed &quot;s/MESSAGE_TEXT/All good from Google Cloude/&quot; \\\n  | kubectl apply -f -</code></pre></div>\n<p>Only one step left now. We need to configure the first cluster with a service entry so the mesh knows how to route calls for <code class=\"language-text\">messanger.default.global</code>. We switch back to the terminal where we have created the first cluster on Amazon. And lookup using the kubeconfig from the second cluster the ip address of the ingress loadbalancer. Next we create a service entry.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Lookup the ingress ip address\nexport CLUSTER_GW_ADDR=$(kubectl \\\n  --kubeconfig=kubeconfig-istio-2.config \\\n  get svc --selector=app=istio-ingressgateway -n istio-system \\\n  -o jsonpath=&#39;{.items[0].status.loadBalancer.ingress[0].ip}&#39;)\necho $CLUSTER_GW_ADDR\n\n# Create a service entry\nkubectl apply -f - &lt;&lt;EOF\napiVersion: networking.istio.io/v1alpha3\nkind: ServiceEntry\nmetadata:\n  name: messenger\nspec:\n  hosts:\n  - messenger.default.global\n  location: MESH_INTERNAL\n  ports:\n  - name: http1\n    number: 3000\n    protocol: http\n  resolution: DNS\n  addresses:\n  - 127.127.42.69\n  endpoints:\n  - address: $CLUSTER_GW_ADDR\n    ports:\n      http1: 15443 # Do not change this port value\nEOF</code></pre></div>\n<p>Now our postcard application should get the message from the second cluster, go back to the browser and refresh the page. You should now see card as below.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.53782668500688%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAABu0lEQVQoz21SPU/DMBTMz2ZmgA0hGCgSEkiVYEDsbExIjAiEKlAr2qSxHef724kbl3PSpqFwg2U/v3vvfH6GUmrdottUVVUUhRCiKIu6rhHJsqwsS9U0qlmFSZKkKeV+lue4MtQAODPKgiB0Xdf3PKyIUEIch6VpWtfi4OxyfH9+Mh49v35o8nqLjhyGYRzHWAPfz9IMEQjJ81wLEeJ4dHF6dcisxzDimsw5RyrWIAhA831/uVxOJhPTXODYk1FalNX1w83o9ujp5U41GXoZpmki27IsbCili8ViNpuhhG0THHtFHYhrv329f31/SlnpzkgFjRAyn8+n0ykKMcZwIaVEQxiEoOM4KAH/mqbR5Rq1Wq0GhukGanPXtkJq9wrUcjnXzy4KOA8jAFGJjWE9bb0TqDtHUQQ7PM8DHw4mCarFyRZg7dzesx3C0BbZMBJ2QjkbACo2stf/QdYS5Tu3UaJoZUM8NCOOKfr1z/tkKTEYe27vwZBbQCdejtR+043nX24/jgZkQAyaaBPSpLUUp7QrAfSbnowYRrV9M7yRdeB7xLYxxoxSj3P8DSOEEgqfKCWuy+H7sLOUWtQPYQYelli44ncAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/75c36dfd28c1fd9ca137ef41c1ed2210/cc182/postcard-2.webp 148w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/f7e40/postcard-2.webp 295w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/1a2f4/postcard-2.webp 590w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/4837b/postcard-2.webp 885w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/2f819/postcard-2.webp 1180w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/9c8b8/postcard-2.webp 1454w\"\n          sizes=\"(max-width: 590px) 100vw, 590px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/75c36dfd28c1fd9ca137ef41c1ed2210/cf440/postcard-2.png 148w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/d2d38/postcard-2.png 295w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/b9e4f/postcard-2.png 590w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/f9b6a/postcard-2.png 885w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/2d849/postcard-2.png 1180w,\n/static/75c36dfd28c1fd9ca137ef41c1ed2210/7aa09/postcard-2.png 1454w\"\n          sizes=\"(max-width: 590px) 100vw, 590px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/75c36dfd28c1fd9ca137ef41c1ed2210/b9e4f/postcard-2.png\"\n          alt=\"postcard\"\n          title=\"postcard\"\n          loading=\"lazy\"\n        />\n      </picture>\n    </span></p>\n<p>That is all you need to do for creating a cross cluster service mesh.</p>\n<h2 id=\"cleanup\"><a href=\"#cleanup\" aria-label=\"cleanup permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cleanup</h2>\n<p>The cleanup steps below assume you created fresh cluster and don’t use them for hosting other applications. The Amazon cluster was created via <code class=\"language-text\">eksctl</code>. This tool actually create cloud formation stacks in Amazon. Before you delete the stack, you need to delete the load balancer created by Istio. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Find the load balancer\naws elb describe-load-balancers | jq -r &quot;.LoadBalancerDescriptions[].LoadBalancerName&quot;\n\n# delete the load balancer  \naws elb delete-load-balancer --load-balancer-name &lt;lb-name&gt;</code></pre></div>\n<p>Now you can delete the cluster, the deletion is a asynchronous process. Ensure you verify the deletion went well. In case it fails, happens many times to me. Delete the VPC and retry the delete via cloud formation.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">delete cluster --name mesh-1 --region=eu-central-1</code></pre></div>\n<p>For Google Cloud the deletion is very easy. Deletion of the cluster will delete all dependent resources.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">cloud container clusters delete --zone europe-west3-b $CLUSTER_NAME</code></pre></div>\n<h2 id=\"acknowledgements\"><a href=\"#acknowledgements\" aria-label=\"acknowledgements permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Acknowledgements</h2>\n<p>The example used in the blog is inspired by a great talk from Matt Turner at the KubeCon - CloudNativeCon 2019 in Barcelona. His talk and example is available in the blog post <a href=\"https://mt165.co.uk/speech/cross-cluster-calls-istio-1-1-kubecon-eu-19/\">Cross-cluster Calls Made Easy with Istio 1.1</a>.</p>","frontmatter":{"title":"Service Mesh","subtitle":"A Multi Cloud Mesh with Istio","date":"2019-07-01","slug":"2019/07/01/cross-cluster-service-mesh","language":null,"tags":["kubernetes","service mesh","cloud","aws","google","docker"],"authors":["niek"],"comments":true,"cover":{"publicURL":"/static/evoluon-9f0ab370c0600504672aced739410981.jpg"},"coverLink":"https://goo.gl/maps/WPrtxowKszHqgLNw9","coverDescription":"Evoluon","imageTw":{"publicURL":"/static/2019-07-01-cross-cluster-service-mesh-tw-13a2cd9ca2ffb15367c61bc0f96f0b9b.png"},"imageFb":{"publicURL":"/static/2019-07-01-cross-cluster-service-mesh-fb-9457b2e90ba4b667567bd462db03e5a5.png"},"asciinema":false}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"2019/07/01/cross-cluster-service-mesh","previous":{"frontmatter":{"title":"Cloud Run","slug":"2019/04/18/cloudrun","type":"post","tags":["cloud","google","docker"],"authors":["niek"]}},"next":{"frontmatter":{"title":"Micro Hack - AWS Amplify","slug":"2019/09/02/automating-the-manual-aws-amplify-deploy","type":"post","tags":["aws","cicd","amplify","cloud"],"authors":["niek"]}}}}}